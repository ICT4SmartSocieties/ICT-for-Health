{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7,9\n",
    "## [see Report 3-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "def standardize (x):\n",
    "    return (x-x.mean())/x.std()\n",
    "\n",
    "def load_data (full_classes=False):\n",
    "\n",
    "    df = pd.read_csv(\"../Data/arrhythmia.csv\", header=None)\n",
    "    df = df.replace({\"?\": np.NaN}).dropna(axis=1, how=\"any\")\n",
    "\n",
    "    if not full_classes:\n",
    "        df.ix[df.iloc[:, -1] > 1, df.columns[-1]] = 2\n",
    "             \n",
    "    df = df.loc[:,(df!=0).any()]\n",
    "    \n",
    "    df_notnorm = df.copy()\n",
    "    df.iloc[:, :-1] = df.iloc[:, :-1].apply(standardize)\n",
    "    \n",
    "    return df_notnorm, df\n",
    "\n",
    "df_notnorm, df = load_data(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NNClassifier (object):\n",
    "\n",
    "    def __init__ (self, df):\n",
    "\n",
    "        self.xks = df.groupby(df.columns[-1]).mean()\n",
    "        self.y = df.iloc[:, :-1]\n",
    "        self.c = df.iloc[:, -1].replace({1:0}).replace({2:1})\n",
    "        \n",
    "    def evaluate_performances (self, prediction, true):\n",
    "        \n",
    "        n_strike = float((prediction == true).sum())\n",
    "        n_miss = float((prediction != true).sum())\n",
    "        strike_rate = n_strike/(n_strike + n_miss)\n",
    "        tp = float(((prediction >= 1) & (true >= 1)).sum())/float((true >= 1).sum())\n",
    "        tn = float(((prediction == 0) & (true == 0)).sum())/float((true == 0).sum())\n",
    "        fp = float(((prediction >= 1) & (true == 0)).sum())/float((true == 0).sum())\n",
    "        fn = float(((prediction == 0) & (true >= 1)).sum())/float((true >= 1).sum())\n",
    "        \n",
    "        return {\n",
    "                \"strike_rate\":strike_rate, \n",
    "                \"sensitivity\":tp, \n",
    "                \"specificity\":tn, \n",
    "                \"false_positive\":fp, \n",
    "                \"false_negative\":fn\n",
    "               }\n",
    "        \n",
    "    def run (self):\n",
    "\n",
    "        N = len(self.y)\n",
    "        F = len(self.y.columns)\n",
    "        \n",
    "        #--- initial settings\n",
    "        nh1 = 257\n",
    "        nh2 = 128\n",
    "        \n",
    "        learning_rate = 3e-2\n",
    "        x = tf.placeholder(tf.float32, [N, F])#inputs\n",
    "        t = tf.placeholder(tf.float32, [N, 1])#desired outputs\n",
    "        \n",
    "        #--- neural netw structure:\n",
    "        w1 = tf.Variable(tf.random_normal(shape=[F, nh1], mean=0.0, stddev=1.0, dtype=tf.float32, name=\"weights1\"))\n",
    "        b1 = tf.Variable(tf.random_normal(shape=[1, nh1], mean=0.0, stddev=1.0, dtype=tf.float32, name=\"biases1\"))\n",
    "        a1 = tf.matmul(x, w1) + b1\n",
    "        z1 = tf.nn.sigmoid(a1)\n",
    "        \n",
    "        w2 = tf.Variable(tf.random_normal([nh1, nh2], mean=0.0, stddev=1.0, dtype=tf.float32, name=\"weights2\"))\n",
    "        b2 = tf.Variable(tf.random_normal([1, nh2], mean=0.0, stddev=1.0, dtype=tf.float32, name=\"biases2\"))\n",
    "        a2 = tf.matmul(z1, w2) + b2\n",
    "        z2 = tf.nn.sigmoid(a2)\n",
    "        \n",
    "        w3 = tf.Variable(tf.random_normal([nh2, 1], mean=0.0, stddev=1.0, dtype=tf.float32, name=\"weights3\"))\n",
    "        b3 = tf.Variable(tf.random_normal([1, 1], mean=0.0, stddev=1.0, dtype=tf.float32, name=\"biases3\"))\n",
    "        y = tf.nn.sigmoid(tf.matmul(z2, w3) + b3)\n",
    "        \n",
    "        #--- optimizer structure\n",
    "        cost = tf.reduce_sum(tf.squared_difference(y, t, name=\"objective_function\"))\n",
    "        optim = tf.train.GradientDescentOptimizer(learning_rate, name=\"GradientDescent\")\n",
    "        optim_op = optim.minimize(cost, var_list=[w1, b1, w2, b2, w2, b3])\n",
    "        \n",
    "        #--- initialize\n",
    "        init = tf.initialize_all_variables()\n",
    "        \n",
    "        #--- run the learning machine\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "        for i in range(1000):\n",
    "            # generate the data\n",
    "            xval = self.y.values\n",
    "            tval = self.c.values.reshape(N, 1)\n",
    "            # train\n",
    "            train_data = {x: xval, t: tval}\n",
    "            sess.run(optim_op, feed_dict = train_data)\n",
    "            c = cost.eval(feed_dict = train_data, session=sess)\n",
    "        self.yhat_train = np.round(y.eval(feed_dict = train_data, session=sess))\n",
    "        self.yhat_train = np.array(self.yhat_train, dtype=np.int32).reshape(len(self.yhat_train),)\n",
    "\n",
    "nnc = NNClassifier(df)\n",
    "nnc.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'false_negative': 0.0,\n",
       " 'false_positive': 0.0,\n",
       " 'sensitivity': 1.0,\n",
       " 'specificity': 1.0,\n",
       " 'strike_rate': 1.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnc.yhat_train\n",
    "nnc.evaluate_performances(nnc.yhat_train, nnc.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "def square_distance (x, xk):\n",
    "    return np.linalg.norm(x - xk)**2\n",
    "\n",
    "def cov_matrix (x):\n",
    "    n = float(len(x))\n",
    "    return 1.0/n * x.T.dot(x)\n",
    "\n",
    "def get_PCA (x):\n",
    "                    \n",
    "    Rx = cov_matrix(x)\n",
    "    eigvals, U = np.linalg.eig(Rx)\n",
    "    L = len(np.where(eigvals.cumsum() < eigvals.sum() * 0.9)[0])    \n",
    "    U = U[:, :L]            \n",
    "    z = x.dot(U)\n",
    "    z = z/z.std()\n",
    "    \n",
    "    return pd.concat([z, df.iloc[:, -1]], axis=1)\n",
    "        \n",
    "def evaluate_performances (yhat, y):\n",
    "    \n",
    "    n_strike = float((yhat == y).sum())\n",
    "    n_miss = float((yhat != y).sum())\n",
    "    strike_rate = n_strike/(n_strike + n_miss)\n",
    "    tp = float(((yhat >= 2) & (y >= 2)).sum())/float((y >= 2).sum())\n",
    "    tn = float(((yhat == 1) & (y == 1)).sum())/float((y == 1).sum())\n",
    "    fp = float(((yhat >= 2) & (y == 1)).sum())/float((y == 1).sum())\n",
    "    fn = float(((yhat == 1) & (y >= 2)).sum())/float((y >= 2).sum())\n",
    "    \n",
    "    return {\n",
    "            \"strike_rate\":strike_rate, \n",
    "            \"sensitivity\":tp, \n",
    "            \"specificity\":tn, \n",
    "            \"false_positive\":fp, \n",
    "            \"false_negative\":fn\n",
    "           }\n",
    "    \n",
    "def run (self):\n",
    "    pass\n",
    "\n",
    "clf = svm.LinearSVC(C=2)\n",
    "x = get_PCA(df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "clf = clf.fit(x, y)\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "scores = cross_val_score(clf, x, y, cv=cv)\n",
    "yhat = cross_val_predict(clf, x, y, cv=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'false_negative': 0.357487922705314,\n",
       " 'false_positive': 0.2693877551020408,\n",
       " 'sensitivity': 0.642512077294686,\n",
       " 'specificity': 0.7306122448979592,\n",
       " 'strike_rate': 0.6902654867256637}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_performances(yhat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
